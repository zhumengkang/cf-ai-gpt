# 🔧 CF AI Chat 变量配置详解

## 📋 目录
- [GitHub Secrets配置](#github-secrets配置)
- [Cloudflare Worker环境变量](#cloudflare-worker环境变量)
- [wrangler.toml配置文件](#wranglertoml配置文件)
- [模型配置详解](#模型配置详解)
- [KV存储配置](#kv存储配置)
- [配置验证方法](#配置验证方法)

## 🔐 GitHub Secrets配置

在GitHub仓库的 **Settings** > **Secrets and variables** > **Actions** 中配置：

### CLOUDFLARE_API_TOKEN
```
类型：Secret
名称：CLOUDFLARE_API_TOKEN
说明：Cloudflare API访问令牌
```

**获取方法：**
1. 访问 [Cloudflare API Tokens](https://dash.cloudflare.com/profile/api-tokens)
2. 点击 **Create Token**
3. 选择 **Custom token**
4. 设置权限：
   ```
   Permissions:
   - Account: Cloudflare Workers:Edit
   - User: User Details:Read
   - Zone: Zone Settings:Read
   - Zone: Zone:Read
   
   Account Resources:
   - Include: All accounts
   
   Zone Resources:
   - Include: All zones
   ```
5. 点击 **Continue to summary** → **Create Token**
6. 复制生成的Token（形如：`1234567890abcdef1234567890abcdef12345678`）

**填写示例：**
```
1234567890abcdef1234567890abcdef12345678
```

### CLOUDFLARE_ACCOUNT_ID
```
类型：Secret
名称：CLOUDFLARE_ACCOUNT_ID
说明：Cloudflare账户ID
```

**获取方法：**
1. 登录 [Cloudflare Dashboard](https://dash.cloudflare.com)
2. 在右侧栏找到 **Account ID**
3. 点击复制按钮

**填写示例：**
```
1a2b3c4d5e6f7g8h9i0j1k2l3m4n5o6p
```

## ⚙️ Cloudflare Worker环境变量

在Worker的 **Settings** > **Variables** > **Environment Variables** 中配置：

### CHAT_PASSWORD
```
变量名：CHAT_PASSWORD
类型：Environment Variable
说明：聊天应用的访问密码
```

**配置要求：**
- 长度：建议8位以上
- 复杂度：包含大小写字母、数字、特殊字符
- 安全性：不要使用常见密码

**填写示例：**
```
MySecure@Chat2024
```

### MODEL_CONFIG
```
变量名：MODEL_CONFIG
类型：Environment Variable
说明：AI模型配置JSON字符串
```

**完整配置值：**
```json
{
  "deepseek-r1": {
    "id": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
    "name": "DeepSeek-R1-Distill-Qwen-32B",
    "description": "基于Qwen2.5的蒸馏模型，超越OpenAI-o1-mini，适合复杂推理",
    "context": 80000,
    "input_price": 0.50,
    "output_price": 4.88,
    "use_messages": true
  },
  "gpt-oss-120b": {
    "id": "@cf/openai/gpt-oss-120b",
    "name": "OpenAI GPT-OSS-120B", 
    "description": "生产级通用模型，适合高推理需求任务",
    "context": 128000,
    "input_price": 0.35,
    "output_price": 0.75,
    "use_messages": false
  },
  "gpt-oss-20b": {
    "id": "@cf/openai/gpt-oss-20b",
    "name": "OpenAI GPT-OSS-20B",
    "description": "低延迟模型，适合专用或本地化应用",
    "context": 128000,
    "input_price": 0.20,
    "output_price": 0.30,
    "use_messages": false
  },
  "llama-4-scout": {
    "id": "@cf/meta/llama-4-scout-17b-16e-instruct",
    "name": "Meta Llama 4 Scout",
    "description": "多模态模型，支持文本和图像理解",
    "context": 131000,
    "input_price": 0.27,
    "output_price": 0.85,
    "use_messages": true
  },
  "qwen-coder": {
    "id": "@cf/qwen/qwen2.5-coder-32b-instruct",
    "name": "Qwen2.5-Coder-32B",
    "description": "代码专用模型，适合代码生成和理解",
    "context": 32768,
    "input_price": 0.66,
    "output_price": 1.00,
    "use_messages": true
  },
  "gemma-3": {
    "id": "@cf/google/gemma-3-12b-it",
    "name": "Gemma 3 12B",
    "description": "多语言多模态模型，支持140+种语言",
    "context": 80000,
    "input_price": 0.35,
    "output_price": 0.56,
    "use_messages": true
  }
}
```

**注意事项：**
- 必须是有效的JSON格式
- 不要有多余的空格或换行
- 如果只想使用部分模型，可以删除对应的配置块

## 📁 wrangler.toml配置文件

### 基本配置
```toml
name = "cf-ai-chat"                # Worker名称，可自定义
main = "src/worker.js"             # 入口文件路径，不要修改
compatibility_date = "2024-01-10"  # 兼容性日期，不要修改
```

### AI绑定配置
```toml
[ai]
binding = "AI"  # AI服务绑定名称，不要修改
```

### KV存储配置
```toml
[kv_namespaces]
binding = "CHAT_HISTORY"                           # KV绑定名称，不要修改
id = "$3d9dc952826b434398ed08d8021cc9b0"           # 生产环境KV命名空间ID
preview_id = "$3d9dc952826b434398ed08d8021cc9b0"   # 预览环境KV命名空间ID
```

**重要：** 
- 将 `id` 和 `preview_id` 替换为您实际的KV命名空间ID
- KV命名空间ID获取方法见《部署指南.md》

### 环境变量配置
```toml
[vars]
CHAT_PASSWORD = "your-secure-password"  # 访问密码，请修改
MODEL_CONFIG = """
{
  "deepseek-r1": {
    "id": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
    "name": "DeepSeek-R1-Distill-Qwen-32B",
    "description": "基于Qwen2.5的蒸馏模型，超越OpenAI-o1-mini，适合复杂推理",
    "context": 80000,
    "input_price": 0.50,
    "output_price": 4.88,
    "use_messages": true
  }
}
"""  # 模型配置JSON，按需修改
```

## 🤖 模型配置详解

### 模型参数说明

每个模型配置包含以下参数：

```json
{
  "model-key": {                    // 模型的唯一标识符
    "id": "CF模型ID",              // Cloudflare的官方模型标识符
    "name": "显示名称",             // 在界面上显示的名称
    "description": "模型描述",       // 模型用途和特点说明
    "context": 上下文窗口大小,        // 支持的最大token数量
    "input_price": 输入价格,         // 输入token价格（美元/百万）
    "output_price": 输出价格,        // 输出token价格（美元/百万）
    "use_messages": true/false      // API调用方式
  }
}
```

### 各字段详细说明

#### id（模型标识符）
- **说明**：Cloudflare Workers AI的官方模型ID
- **格式**：`@cf/provider/model-name`
- **注意**：不可修改，必须与CF官方保持一致

**当前支持的模型ID：**
```
@cf/deepseek-ai/deepseek-r1-distill-qwen-32b
@cf/openai/gpt-oss-120b
@cf/openai/gpt-oss-20b
@cf/meta/llama-4-scout-17b-16e-instruct
@cf/qwen/qwen2.5-coder-32b-instruct
@cf/google/gemma-3-12b-it
```

#### name（显示名称）
- **说明**：在用户界面上显示的模型名称
- **格式**：任意字符串
- **示例**：`"DeepSeek-R1-Distill-Qwen-32B"`
- **可修改**：是，可以自定义更友好的名称

#### description（模型描述）
- **说明**：模型的用途和特点说明
- **格式**：任意字符串
- **示例**：`"基于Qwen2.5的蒸馏模型，适合复杂推理"`
- **可修改**：是，可以自定义描述内容

#### context（上下文窗口）
- **说明**：模型支持的最大token数量
- **格式**：正整数
- **单位**：tokens
- **示例**：`80000`
- **可修改**：否，必须与官方规格一致

#### input_price（输入价格）
- **说明**：处理输入文本的价格
- **格式**：浮点数
- **单位**：美元/百万tokens
- **示例**：`0.50`
- **可修改**：建议与官方保持同步

#### output_price（输出价格）
- **说明**：生成输出文本的价格
- **格式**：浮点数
- **单位**：美元/百万tokens
- **示例**：`4.88`
- **可修改**：建议与官方保持同步

#### use_messages（API调用方式）
- **说明**：模型的API调用参数格式
- **格式**：布尔值（true/false）
- **含义**：
  - `true`：使用OpenAI风格的messages参数
  - `false`：使用instructions + input参数

**使用messages格式的模型：**
- DeepSeek-R1-Distill-Qwen-32B
- Meta Llama 4 Scout
- Qwen2.5-Coder-32B
- Gemma 3 12B

**使用instructions格式的模型：**
- OpenAI GPT-OSS-120B
- OpenAI GPT-OSS-20B

### 自定义模型配置示例

如果您只想使用部分模型，可以这样配置：

```json
{
  "deepseek": {
    "id": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
    "name": "DeepSeek推理模型",
    "description": "适合复杂数学和逻辑推理",
    "context": 80000,
    "input_price": 0.50,
    "output_price": 4.88,
    "use_messages": true
  },
  "gpt-fast": {
    "id": "@cf/openai/gpt-oss-20b",
    "name": "GPT快速版",
    "description": "低延迟，适合日常对话",
    "context": 128000,
    "input_price": 0.20,
    "output_price": 0.30,
    "use_messages": false
  }
}
```

## 💾 KV存储配置

### KV Namespace Bindings
在Worker的 **Settings** > **Variables** > **KV Namespace Bindings** 中配置：

```
Variable name: CHAT_HISTORY
KV namespace: 选择您创建的KV命名空间
```

### AI Bindings
在Worker的 **Settings** > **Variables** > **AI Bindings** 中配置：

```
Variable name: AI
```

## ✅ 配置验证方法

### 1. 验证GitHub Secrets
在GitHub仓库的Actions页面查看工作流运行状态：
- ✅ 绿色：配置正确
- ❌ 红色：配置有误，查看错误日志

### 2. 验证Worker环境变量
1. 访问Worker域名，应返回JSON状态信息
2. 访问 `/api/models`，应返回模型列表
3. 如果返回错误，检查环境变量配置

### 3. 验证前端连接
1. 打开前端页面
2. 输入Worker域名
3. 输入正确密码
4. 选择模型并发送测试消息

### 4. 验证KV存储
1. 在聊天界面发送消息
2. 刷新页面
3. 点击"加载历史记录"
4. 如果能看到之前的消息，说明KV配置正确

## 🚨 常见配置错误

### 错误1：KV命名空间ID不正确
**症状**：历史记录无法保存
**解决**：检查wrangler.toml中的KV ID是否与实际创建的一致

### 错误2：MODEL_CONFIG格式错误
**症状**：无法加载模型列表
**解决**：验证JSON格式是否正确，可使用在线JSON验证工具

### 错误3：API Token权限不足
**症状**：GitHub Actions部署失败
**解决**：重新创建API Token，确保包含Workers编辑权限

### 错误4：密码配置错误
**症状**：输入密码后验证失败
**解决**：检查Worker环境变量中的CHAT_PASSWORD设置

### 错误5：模型ID错误
**症状**：发送消息后返回模型不存在错误
**解决**：确认模型ID与Cloudflare官方文档一致

## 🔄 配置更新

### 修改密码
1. 更新Worker环境变量 `CHAT_PASSWORD`
2. 或修改wrangler.toml中的 `CHAT_PASSWORD`
3. 重新部署

### 添加新模型
1. 在 `MODEL_CONFIG` 中添加新的模型配置
2. 确保模型ID正确
3. 重新部署

### 修改模型价格
1. 更新对应模型的 `input_price` 和 `output_price`
2. 重新部署

记住：每次修改配置后都需要重新部署才能生效！
