# 🚀 CF AI Chat 详细部署指南

## 📖 目录
- [项目介绍](#项目介绍)
- [环境准备](#环境准备)
- [方式一：GitHub自动部署（推荐）](#方式一github自动部署推荐)
- [方式二：手动部署](#方式二手动部署)
- [详细配置说明](#详细配置说明)
- [常见问题解决](#常见问题解决)
- [使用教程](#使用教程)

## 📋 项目介绍

CF AI Chat 是一个基于 Cloudflare Workers AI 的多模型聊天应用，具有以下特点：

- 🔐 **密码保护**：配置文件设置访问密码，安全可靠
- 🤖 **多模型支持**：支持6种不同AI模型（DeepSeek、OpenAI、Llama、Qwen、Gemma）
- 📚 **历史记录**：使用KV存储保存聊天历史
- 💰 **费用透明**：显示每个模型的具体收费标准
- 📱 **响应式设计**：支持PC和移动设备
- ⚡ **纯文本回复**：返回纯文本而非JSON格式

## 🛠️ 环境准备

### 1. GitHub账户
- 需要一个GitHub账户用于托管代码
- 如果没有，请访问 [GitHub](https://github.com) 注册

### 2. Cloudflare账户
- 需要Cloudflare账户，免费套餐即可
- 访问 [Cloudflare](https://cloudflare.com) 注册
- 确保启用了 **Workers AI** 功能

### 3. 创建KV命名空间

#### 步骤1：登录Cloudflare Dashboard
1. 访问 [Cloudflare Dashboard](https://dash.cloudflare.com)
2. 使用您的账户登录

#### 步骤2：进入Workers控制台
1. 在左侧菜单栏点击 **Workers & Pages**
2. 点击 **KV** 标签页

#### 步骤3：创建KV命名空间
1. 点击 **Create a namespace** 按钮
2. 输入命名空间名称，例如：`cf-ai-chat-history`
3. 点击 **Add** 创建

#### 步骤4：记录命名空间ID
创建完成后，页面会显示命名空间ID，类似：`$3d9dc952826b434398ed08d8021cc9b0`
**请记录这个ID，后续配置需要用到**

## 🔄 方式一：GitHub自动部署（推荐）

这种方式最简单，只需要配置一次，后续修改代码会自动部署。

### 第一步：Fork项目

1. 访问本项目的GitHub页面
2. 点击右上角的 **Fork** 按钮
3. 选择Fork到您的个人账户
4. 等待Fork完成

### 第二步：获取Cloudflare API密钥

#### 2.1 获取API Token
1. 访问 [Cloudflare API Tokens页面](https://dash.cloudflare.com/profile/api-tokens)
2. 点击 **Create Token** 按钮
3. 选择 **Custom token** 模板
4. 配置权限：
   ```
   Permissions:
   - Account: Cloudflare Workers:Edit
   - Zone: Zone Settings:Read
   - Zone: Zone:Read
   
   Account Resources:
   - Include: All accounts
   
   Zone Resources:
   - Include: All zones
   ```
5. 点击 **Continue to summary**
6. 点击 **Create Token**
7. **复制并保存Token**（只显示一次）

#### 2.2 获取Account ID
1. 在Cloudflare Dashboard首页
2. 右侧栏可以看到 **Account ID**
3. 点击复制按钮保存

### 第三步：配置GitHub Secrets

1. 进入您Fork的仓库
2. 点击 **Settings** 标签页
3. 在左侧菜单找到 **Secrets and variables** > **Actions**
4. 点击 **New repository secret** 添加以下两个密钥：

#### Secret 1: CLOUDFLARE_API_TOKEN
- **Name**: `CLOUDFLARE_API_TOKEN`
- **Secret**: 粘贴步骤2.1中获取的API Token

#### Secret 2: CLOUDFLARE_ACCOUNT_ID
- **Name**: `CLOUDFLARE_ACCOUNT_ID`  
- **Secret**: 粘贴步骤2.2中获取的Account ID

### 第四步：修改配置文件

#### 4.1 编辑wrangler.toml
1. 在您的仓库中，点击 `wrangler.toml` 文件
2. 点击铅笔图标（编辑）
3. 修改以下内容：

```toml
name = "cf-ai-chat"
main = "src/worker.js"
compatibility_date = "2024-01-10"

[ai]
binding = "AI"

[kv_namespaces]
binding = "CHAT_HISTORY"
id = "$3d9dc952826b434398ed08d8021cc9b0"        # 替换为您的KV命名空间ID
preview_id = "$3d9dc952826b434398ed08d8021cc9b0"  # 替换为您的KV命名空间ID

[vars]
CHAT_PASSWORD = "your-secure-password-here"       # 修改为您的访问密码
MODEL_CONFIG = """
{
  "deepseek-r1": {
    "id": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
    "name": "DeepSeek-R1-Distill-Qwen-32B",
    "description": "基于Qwen2.5的蒸馏模型，超越OpenAI-o1-mini，适合复杂推理",
    "context": 80000,
    "input_price": 0.50,
    "output_price": 4.88,
    "use_messages": true
  },
  "gpt-oss-120b": {
    "id": "@cf/openai/gpt-oss-120b",
    "name": "OpenAI GPT-OSS-120B", 
    "description": "生产级通用模型，适合高推理需求任务",
    "context": 128000,
    "input_price": 0.35,
    "output_price": 0.75,
    "use_messages": false
  },
  "gpt-oss-20b": {
    "id": "@cf/openai/gpt-oss-20b",
    "name": "OpenAI GPT-OSS-20B",
    "description": "低延迟模型，适合专用或本地化应用",
    "context": 128000,
    "input_price": 0.20,
    "output_price": 0.30,
    "use_messages": false
  },
  "llama-4-scout": {
    "id": "@cf/meta/llama-4-scout-17b-16e-instruct",
    "name": "Meta Llama 4 Scout",
    "description": "多模态模型，支持文本和图像理解",
    "context": 131000,
    "input_price": 0.27,
    "output_price": 0.85,
    "use_messages": true
  },
  "qwen-coder": {
    "id": "@cf/qwen/qwen2.5-coder-32b-instruct",
    "name": "Qwen2.5-Coder-32B",
    "description": "代码专用模型，适合代码生成和理解",
    "context": 32768,
    "input_price": 0.66,
    "output_price": 1.00,
    "use_messages": true
  },
  "gemma-3": {
    "id": "@cf/google/gemma-3-12b-it",
    "name": "Gemma 3 12B",
    "description": "多语言多模态模型，支持140+种语言",
    "context": 80000,
    "input_price": 0.35,
    "output_price": 0.56,
    "use_messages": true
  }
}
"""
```

**重要说明：**
- 将 `id` 和 `preview_id` 替换为您在准备工作中创建的KV命名空间ID
- 将 `CHAT_PASSWORD` 修改为您想要的访问密码（建议使用复杂密码）

4. 滚动到页面底部，填写提交信息：
   - **Commit message**: `更新配置文件`
5. 点击 **Commit changes**

### 第五步：启用GitHub Pages

1. 在您的仓库中，点击 **Settings** 标签页
2. 在左侧菜单找到 **Pages**
3. 在 **Source** 下拉菜单中选择 **GitHub Actions**
4. 保存设置

### 第六步：触发部署

1. 在仓库主页，点击 **Actions** 标签页
2. 您应该看到一个工作流正在运行或等待运行
3. 如果没有，可以手动触发：
   - 修改任何文件（比如README.md添加一个空格）
   - 提交更改

### 第七步：获取访问地址

部署完成后，您将获得两个地址：

#### 前端页面地址：
`https://yourusername.github.io/cf-gpt-oss`
（将yourusername替换为您的GitHub用户名）

#### API端点地址：
1. 进入Cloudflare Dashboard
2. 找到新创建的Worker（名为cf-ai-chat）
3. 复制Worker的域名，类似：`https://cf-ai-chat.youraccount.workers.dev`

## 🔧 方式二：手动部署

如果您不想使用GitHub自动部署，可以选择手动部署。

### 第一步：部署Worker

#### 1.1 进入Cloudflare Dashboard
1. 访问 [Cloudflare Dashboard](https://dash.cloudflare.com)
2. 点击 **Workers & Pages**

#### 1.2 创建Worker
1. 点击 **Create application**
2. 选择 **Create Worker**
3. 输入Worker名称：`cf-ai-chat`
4. 点击 **Deploy**

#### 1.3 上传代码
1. 在Worker编辑页面，删除默认代码
2. 复制 `src/worker.js` 文件的全部内容
3. 粘贴到编辑器中
4. 点击 **Save and Deploy**

### 第二步：配置Worker环境

#### 2.1 配置KV绑定
1. 在Worker详情页面，点击 **Settings** 标签页
2. 找到 **Variables** 部分
3. 在 **KV Namespace Bindings** 点击 **Add binding**
4. 填写：
   - **Variable name**: `CHAT_HISTORY`
   - **KV namespace**: 选择您创建的KV命名空间
5. 点击 **Save**

#### 2.2 配置AI绑定
1. 在 **AI Bindings** 部分点击 **Add binding**
2. 填写：
   - **Variable name**: `AI`
3. 点击 **Save**

#### 2.3 配置环境变量
1. 在 **Environment Variables** 部分点击 **Add variable**

**变量1：CHAT_PASSWORD**
- **Variable name**: `CHAT_PASSWORD`
- **Value**: `your-secure-password`（您的访问密码）

**变量2：MODEL_CONFIG**
- **Variable name**: `MODEL_CONFIG`
- **Value**: 
```json
{
  "deepseek-r1": {
    "id": "@cf/deepseek-ai/deepseek-r1-distill-qwen-32b",
    "name": "DeepSeek-R1-Distill-Qwen-32B",
    "description": "基于Qwen2.5的蒸馏模型，超越OpenAI-o1-mini，适合复杂推理",
    "context": 80000,
    "input_price": 0.50,
    "output_price": 4.88,
    "use_messages": true
  },
  "gpt-oss-120b": {
    "id": "@cf/openai/gpt-oss-120b",
    "name": "OpenAI GPT-OSS-120B", 
    "description": "生产级通用模型，适合高推理需求任务",
    "context": 128000,
    "input_price": 0.35,
    "output_price": 0.75,
    "use_messages": false
  },
  "gpt-oss-20b": {
    "id": "@cf/openai/gpt-oss-20b",
    "name": "OpenAI GPT-OSS-20B",
    "description": "低延迟模型，适合专用或本地化应用",
    "context": 128000,
    "input_price": 0.20,
    "output_price": 0.30,
    "use_messages": false
  },
  "llama-4-scout": {
    "id": "@cf/meta/llama-4-scout-17b-16e-instruct",
    "name": "Meta Llama 4 Scout",
    "description": "多模态模型，支持文本和图像理解",
    "context": 131000,
    "input_price": 0.27,
    "output_price": 0.85,
    "use_messages": true
  },
  "qwen-coder": {
    "id": "@cf/qwen/qwen2.5-coder-32b-instruct",
    "name": "Qwen2.5-Coder-32B",
    "description": "代码专用模型，适合代码生成和理解",
    "context": 32768,
    "input_price": 0.66,
    "output_price": 1.00,
    "use_messages": true
  },
  "gemma-3": {
    "id": "@cf/google/gemma-3-12b-it",
    "name": "Gemma 3 12B",
    "description": "多语言多模态模型，支持140+种语言",
    "context": 80000,
    "input_price": 0.35,
    "output_price": 0.56,
    "use_messages": true
  }
}
```

2. 点击 **Save and deploy**

### 第三步：部署前端页面

#### 选项1：GitHub Pages
1. 创建一个新的GitHub仓库
2. 上传 `index.html` 文件
3. 在仓库Settings中启用GitHub Pages
4. 选择source为main分支

#### 选项2：Cloudflare Pages
1. 在Cloudflare Dashboard中选择 **Pages**
2. 点击 **Create a project**
3. 选择 **Upload assets**
4. 上传 `index.html` 文件
5. 设置项目名称并部署

#### 选项3：其他静态托管服务
- Netlify
- Vercel
- 或任何支持静态文件的服务

## ⚙️ 详细配置说明

### 密码配置
```toml
CHAT_PASSWORD = "your-secure-password"
```
- 这是访问聊天应用的密码
- 建议使用包含字母、数字、特殊字符的复杂密码
- 密码长度建议8位以上

### 模型配置详解

每个模型配置包含以下字段：

```json
{
  "model-key": {
    "id": "CF模型标识符",
    "name": "显示名称", 
    "description": "模型描述",
    "context": 上下文窗口大小,
    "input_price": 输入价格每百万tokens,
    "output_price": 输出价格每百万tokens,
    "use_messages": 是否使用messages参数
  }
}
```

**字段说明：**
- `id`: Cloudflare的模型标识符，不可修改
- `name`: 在界面上显示的模型名称，可自定义
- `description`: 模型的用途说明，可自定义
- `context`: 模型支持的最大上下文token数
- `input_price`: 输入token的价格（美元/百万tokens）
- `output_price`: 输出token的价格（美元/百万tokens）
- `use_messages`: 
  - `true`: 使用OpenAI风格的messages参数
  - `false`: 使用instructions+input参数

### KV命名空间配置
```toml
[kv_namespaces]
binding = "CHAT_HISTORY"
id = "your-kv-namespace-id"
preview_id = "your-kv-namespace-id"
```
- `binding`: 在代码中引用KV的变量名
- `id`: 生产环境的KV命名空间ID
- `preview_id`: 预览环境的KV命名空间ID（可与id相同）

## 🔧 常见问题解决

### 问题1：GitHub Actions部署失败

**错误信息**：`Authentication error`
**解决方案**：
1. 检查CLOUDFLARE_API_TOKEN是否正确设置
2. 确认API Token权限是否包含Workers编辑权限
3. 检查CLOUDFLARE_ACCOUNT_ID是否正确

**错误信息**：`KV namespace not found`
**解决方案**：
1. 确认KV命名空间ID是否正确
2. 检查KV命名空间是否已创建
3. 确认Account ID是否匹配

### 问题2：前端无法连接API

**症状**：页面显示网络错误
**解决方案**：
1. 检查Worker是否成功部署
2. 确认Worker域名地址是否正确
3. 检查Worker的CORS设置
4. 尝试直接访问Worker地址测试

### 问题3：密码验证失败

**症状**：输入密码后提示错误
**解决方案**：
1. 检查Worker环境变量中的CHAT_PASSWORD设置
2. 确认密码输入无误（注意大小写）
3. 检查MODEL_CONFIG环境变量是否正确设置

### 问题4：模型调用失败

**症状**：发送消息后返回错误
**解决方案**：
1. 确认Cloudflare账户已启用Workers AI
2. 检查模型ID是否正确
3. 确认Account余额充足
4. 检查模型配置中的use_messages设置

### 问题5：历史记录无法保存

**症状**：刷新页面后历史记录丢失
**解决方案**：
1. 检查KV命名空间绑定是否正确
2. 确认CHAT_HISTORY绑定名称正确
3. 检查KV命名空间权限设置

## 📚 使用教程

### 第一次使用

1. **访问应用**
   - 打开前端页面地址
   - 如果看到API配置页面，输入Worker域名

2. **配置API端点**
   - 输入您的Worker域名
   - 格式：`https://cf-ai-chat.youraccount.workers.dev`
   - 点击"确认设置"

3. **身份验证**
   - 输入您在配置文件中设置的密码
   - 点击"验证"按钮

4. **选择模型**
   - 从下拉菜单选择AI模型
   - 查看模型的详细信息（价格、上下文限制等）

5. **开始聊天**
   - 在输入框中输入问题
   - 按Enter或点击发送按钮
   - 等待AI回复

### 功能使用

#### 查看历史记录
- 点击"加载历史记录"按钮
- 系统会显示之前的对话

#### 清空历史记录
- 点击"清空历史"按钮
- 确认后会删除所有聊天记录

#### 切换模型
- 随时可以从下拉菜单切换不同的AI模型
- 每个模型有不同的特点和收费标准

#### 查看token使用情况
- 每条AI回复下方会显示使用的token数量
- 帮助您了解使用成本

### 成本控制建议

1. **选择合适的模型**
   - 日常聊天：使用gpt-oss-20b（价格最低）
   - 复杂推理：使用deepseek-r1
   - 代码相关：使用qwen-coder

2. **控制上下文长度**
   - 系统会自动限制历史记录长度
   - 避免超长对话导致成本增加

3. **监控使用量**
   - 定期检查Cloudflare账户余额
   - 关注token使用统计

## 🎉 部署完成

恭喜！您已经成功部署了CF AI Chat应用。

**您现在拥有：**
- ✅ 多模型AI聊天功能
- ✅ 密码保护的安全访问
- ✅ 自动保存的聊天历史
- ✅ 透明的费用显示
- ✅ 响应式的用户界面
- ✅ 纯文本的AI回复

**技术支持：**
如果在部署过程中遇到问题，请检查：
1. 所有配置是否正确填写
2. Cloudflare服务是否正常
3. GitHub Actions是否成功运行
4. 网络连接是否正常

祝您使用愉快！🚀
